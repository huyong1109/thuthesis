\chapter{相关工作}
\label{cha:related}

\section{海洋模式正压模态求解技术}
\label{related:baro}
 
\section{迭代算法中的预处理技术}
\label{related:precond}

我们这里简单的从两个方面介绍一下相关工作： 一是提高通用的并行环境中共轭梯度法效率的工作，二是针对海洋模式中的共轭梯度法的效率的改进。
在第一个方面， 减少共轭梯度法的全局通信的开销在这个算法被并行化之后就一直是研究的热点。 
这方面工作比较好的一个综述可以参见\cite{ghysels2014}。 
这个领域最早的成果是在标准的共轭梯度法的基础上做算法的修正从而减少全局归约操作的次数， 比如在海洋模式POP中被采用的ChronGear方法\cite{dAzevedo1999lapack} 。 这些方法至今仍然被广泛的使用着。 
早期还有s-步方法\cite{chron1989} 和最近的一些变种（比如论文\inlinecite{hoemmen2010}）也能够减少全局通信， 但是这些方法很难结合稍微复杂一点的预处理方法使用。、
另外，最近也有一些工作提出来将全局归约操作和矩阵向量乘积操作利用流水线的方式进行重叠\cite{ghysels2014}，从而提高并行共轭梯度法的效率。  
我们采用与论文\inlinecite{gutknecht2002chebyshev}中不一样的思路。
我们完全的摒弃了共轭梯度法，取而代之的是一个更为简单的不包含全局归约操作的迭代算法。 



针对海洋模式， 有很多工作都是关于如何减少求解器中的通信瓶颈的。 
在论文\cite{Worley:2011:PCE:2063384.2063457}中， 他们在正压模态中采用OpenMP并行技术，从而提高了海洋模式在大核数上的性能。 
另一个比较常见的减少通信开销的策略是陆地点的移除\cite{dennis2007inverse,dennis2008scaling}。 
使用空间填充曲线来划分网格，不仅能够改善负载均衡，还能够通过去掉全是陆地点的块来减少需要参与通信的处理器核心的数目，从而减少通信的开销。 
这一方法使得在30,000处理器核心上的模拟速度提升了近一倍。 
另外，早起还有一些工作尝试将并行大洋环流模式中的计算和通信相重叠 \cite{beare1997optimisation}，以及通过减少边界缓存区域的大小来减少通信开销。 
尽管这些方法都能够对性能有一定的提升， 但是他们并没有完全的消除掉全局归约操作的瓶颈。 
事实上， 我们的早起论文\inlinecite{hu2013scalable}中给出了一个比较有潜力的工作，通过用Chebyshev迭代方法来替换掉共轭梯度法，
在独立版本的海洋模式POP中取得了很好的效果。 

 
最后，我们放弃了串行效率很高的共轭梯度法，使得我们不得不去寻找正压模态中一个可用的更加高效的预处理子。 
这里，我们提一下为了减少高分辨率海洋模式中正压模态求解的几个预处理技术。 
多项式预处理技术和局部逆预处理技术被证明是加速并行大洋环流模式中的共轭梯度法的收敛的比较好的技术\cite{smith1992parallel}。 
最近，Max Planck研究中心的海洋模式MPIOM采用了一种基于不完全Cholesky分解的预处理子。它能够改善共轭梯度法在大核数上的运行效率 \cite{adamidis2011high}。


  
共轭梯度法中的预处理方法自从上世纪90年代以来就一直备受重视。 
很多的线性系统在采用了适当的预处理子之后，预处理共轭梯度法只需要少数几步迭代就能够收敛。 
然是，大多数的最有效的预处理技术， 比如说不完全的Cholesky分解和不完全的LU分解，在海洋模式中并不是十分的有效。 
海洋模式中的椭圆方程组需要为之设计专门的可并行化的预处理子。 
在1985年，Concus 等人\cite{concus1985block}采用系数矩阵的逆的一个条带状的近似，来对椭圆微分方程上的共轭梯度法进行预处理，结果取得了比其他通用的预处理方法更高的效率。 
Smith等人\cite{smith1992parallel}采用多项式预处理的方法和一个局部近似逆的预处理方法来加速并行大洋环流模式中的共轭梯度法的收敛。 
Adamidis等人 \cite{adamidis2011high} 在全球海洋海冰模式MPIOM中采用了一个不完全的Cholesky预处理子，在提高预处理共轭梯度法的性能的同时，也改善了它的可扩展性。 
Watanabe \cite{Watanabe2006pcg} 设计了一个与重叠区域分解法相结合的预处理共轭梯度法来加速收敛，同时减少了处理单元之间的通信开销。 




    
目前已经有很多的研究工作专门研究如何提高海洋模式中隐式自由海表面问题中的椭圆方程的求解效率。 
现在有很多的可选方案来缓解大规模并行环境中的预处理的共轭梯度法所固有的比较差的可扩展性。 
 减少通信的频率同样可以减轻正压模态中的性能瓶颈。 
 早在1997年，  Beare　\cite{beare1997optimisation}等人就提出来，通过增大边界通信缓存区域的块的大小以及将重新和计算相重叠可以提高并行大洋环流模式的性能。 
  

这篇文章所给出的方案结合了以上的两条策略，来提高正压求解器的性能。 
P-CSI求解器能够去掉共轭梯度法及其变化形式中所需要的全局通信。　
同时，它支持EVP预处理子。这个EVP预处理子加速求解器的收敛的效果与海洋模式中其他的预处理方法相当。 



预处理共轭梯度法的数据局部性比较差，而且很多操作只能串行执行，导致以上的改进方案的效果都十分有限。 
其他一些工作利用异构加速平台，比如说GPUs \cite{cuomo2012pcg} 和FPGAs \cite{Shida2007}来实现对预处理共轭梯度法的加速。 
Cuomo 等人\cite{cuomo2012pcg}在全球环流海洋数值模式中引入了稀疏近似逆预处方法，并且利用一个科学计算库将其实现在GPU上。 
Shida 等人\cite{Shida2007}将海洋模式中的正压模态移植到FPGAs上，并且发现发现当适当的使用块上内存和流式的直接内存访问，一块100MHz的FPGA卡的性能能与1GHz的处理相当。 
GPUs和FPGAs还能够减少正压模态中的全局通信开销。这些设备跟传统的CPU相比有更强的计算能力和更大的内存，因此我们只需要使用很少的几块加速卡就能够实现只有在大规模并行环境下才能计算的任务。

\section{气候模式正确性验证}
\label{related:veify}


\section{本章小结}
\label{related:Conclude}