 
\subsection{研究动机}

 
文章 \cite{yong2015} 中给出来的求解器验证性工作很有启发性，而且完全满足目前的需求。 
但是它仍然有几个遗留问题没有解决，这促使我们研发了一个类似于CAM-ECT这样的更强大的针对CESM-POP数据的评测工具。 
第一，一个更通用的海洋模式POP的验证性工具首先考虑的是海洋中空间的变化特点，这个特点比大气中的要更加突出。
CAM-ECT和文章\cite{yong2015} 中的RMSZ方法是利用空间的平均值的差别来作评估，目前还不清楚这样的策略是否有足够的能力来检测海洋中的正确性表达问题以及模式本身的误差。
第二，由于CESM-POP的相互独立的诊断性变量要比大气模式CAM少很多，因此我们需要重新思考了一下一致性检测的量化指标。
第三，不同的衡量指标的选择促使我们进一步检查集合模拟的大小应该如何选择。
在文章\cite{yong2015} 中，四十个实例组成的集合模拟就足以检查出线性求解器中的误差，而这个集合模拟的大小并没有在更通用的环境中进行实验验证。
而且，这个大小要比CAM-ECT中使用的默认大小151要小很多。
最后，海洋和大气中时间尺度的不同也促使我们去研究集合模拟的模拟时间究竟多长最为合适。 
由于海洋中的时间尺度比大气中的要长一些， 直观上讲，CESM-POP中额统计学一致性检测工具需要的集合模拟的模拟时间应该会更长一些。 
值得一提的是，图\ref{fig:rmsz_temp_ens} 似乎又有悖于我们的这个假设。 
我们可以看出来，当收敛条件足够严格的时候（收敛条件小于$10^{-12}$时）， 均方根标准分在模式运行几个月之后随着时间的推移而逐渐减小。
这表明，我需要进一步的研究一致性检测所需要的模拟时间的长度。 
实际上， 图\ref{fig:rmsz_temp_ens}可以看出，这个给定的1度分辨率的海洋数据是相对确定的，在求解器中引入的误差足够小（也就是收敛条件足够小的时候）初值场中的误差在模拟了一年之后逐渐的耗散掉了。


%----------------------------------------------------------------------------
%----------------------------------------------------------------------------
%----------------------------------------------------------------------------


\section{CESM-POP的新的一致性检测工具}\label{sec:newtest}

 
在CESM-ECT工具集中扩充CESM-POP一致性检测的工具（我们记为POP-ECT），我们需要一个能够反映海洋模式自身不确定性的恰当的集合模拟结果，并且开发一种针对海洋自身特点的方法。
这里我们首先讨论一下如何构造这个集合模拟结果，然后介绍一下新的测试工具的流程。 
\subsection{POP数据集合的构造}\label{sec:ensemble}

 
我们通过与很多被认可的海洋状态组成的集合作对比，来评估CESM-POP的输出数据与数据集合在统计学上的差别是否明显。
明显则我们认为这个输出数据与给定的数据集合是不同的气候状态。 
因此，将CESM-ECT应用到CESM-POP数据的第一步就是要构造出一个合适的数据集合。 
很明显，数据集合的组成对于测试的有效性来说至关重要，而且这些数据必须在一个被认可的机器上采用被认可的CESM版本来生成。
这里，与CAM相比，海洋模式的诊断变量要少很多，相互独立的诊断变量有：温度（TEMP），海表高度（SSH），盐度（SALT）， 以及与模式网格相对应的经向和纬想得速度（分别为UVEL和VVEL）。
这五个变量中，只要海表高度SSH是二维变量，其他都是三维变量。 

 
在POP-ECT中，我们够早了一个由$N_{ens}$模拟结果组成的数据集合 $E$， 记为 $E =\{E_1, E_2, \dots, E_{N_{ens}} \}$。
这些模拟结果与指定的默认版本之间的唯一不同是在初始的海洋温度场中加入$\mathcal{O}(10^{-14})$量级的随机扰动。 
这个初值扰动的大小和双精度浮点数的舍入误差在一个量级，因此它应该不会造成气候上的改变。
这个数据集合的成员的数量必须足够的多才能够生成一个比较有表达力的分布，但是这个数量又要足够的小，因为增加一个成员就以为增加一份计算开销。 
我们将在稍后的第\ref{sec:ens}节中讨论数据集合的大小的选择 。这里的讨论和之后的实验我们都采用 $N_{ens} \;=\; 40$这个配置。
我们的实验表明，如果只是用来做一致性测试，这个大小的集合 足以充分的反应海洋的内在的不确定性。
模拟数据集合包含有在每个点上五个POP诊断变量（TEMP, SSH, SALT, UVEL和VVEL）的月平均数据。
每一个这样的变量$X$都包含有$N_X$个网格点，记为${X} = \{ x_1, x_2, \dots, x_{N_X}\}$， 这里$x_i$ 表示在网格点$i$上变量$X$的月平均值。
我们收集了$T$个月份的数据（即$T$个时间片的月平均数据）。

 
CESM-ECT方法的下一步是量化数据集合的分布特征，进而为行的模拟结果提供评估依据。
这个数据集合的统计特诊描述被存在一个叫做数据集合汇总的文件中，并且这个文件会被贴上生成这些模拟结果的CESM自带的软件标签。
当这个汇总文件一旦生成， 数据集合中$N_{ens}$个模拟结果的历史文件就不需要继续保存了。 
回忆一下CAM数据所使用的方法，CAM-ECT会计算每个变量在每个点上的可用的年平均数据的全球面积加权平均值。
这些计算结果就构成了每个变量的$N_{ens}$个全球平均。 
然而， 这个方法采用的全面积加权平均不能很好的应用在海洋模式数据中，因为海洋模式的不确定性相比于大气模式数据来说，在网格点上的一致性更差一些。
因此，我们需要更多的考虑到空间上的分布特诊。 


比如，我们考虑一个由$N_{ens} \;=\; 40$个使用1度分辨的海洋模式POP作为海洋模式分量的CESM模拟$T\;=\;36$个月得到的模拟结果组成的数据集合。 
图 \ref{fig:SST_STD_all}中给出的是数据集合的1,12,24和36个模拟月份中海表温度（SST）的标准方差的空间分布。
注意到这里海表温度SST仅仅只是三维变量TEMP的最上面一层（更加准确的说，是10米的海洋表层）。
图 \ref{fig:SST_STD_all}可以看出来，标准方差远远不是空间一致分布的，不同的网格点之间的值相差好几个数量级（注意颜色刻度尺的刻度）。 
从1月份到12月份的变化也十分明显，这主要是与模式冷启动时由于流体动力学不稳定性造成的模式不稳定相关。  
在模拟一年之后，在热带区域出现的标准差最大表明集合模拟中热带不稳定波的增长带来了更大的不确定性\citep{legeckis1977}。
由于赤道区域的网格分辨率更细一些（$1/3^\circ$左右），这些大的可变性在 赤道地区很容易被强化。 
在几个主要的海洋环流系统区域内，也有几个比较大的标准方差集中区域。
从12个月到36的变化相对较小，这表明相应的物理不稳定性由于海洋的耗散将不会继续增长。
鉴于图 \ref{fig:SST_STD_all}中明显的不确定性，文章\cite{yong2015} 中的均方根标准分策略可能在某些不确定性很小的区域由于方程\ref{e:rmsz}中的分母太小引入不必要的潜在误差。
这里强调一下，图\ref{fig:SST_STD_all} 中不确定性的大小确实是与分辨率有关的，并且，图\ref{fig:SST_STD_all} 中的结果只适应于有耗散的低分辨率海洋模式，比如说目前大部分气候研究中所使用的1度的CESM-POP。


 
综上所述，为了构造出一个在CESM-POP数据上比较健壮的集合统计学一致性检测工具，我们必须得到一个既包含有空间信息，又包含有时间信息的数据集合。
特别的，POP-ECT构造的集合综述文件中第$T$ 个 月份的时间片CESM-POP数据包含有：
\begin{itemize}
 \item $N_{var} \times N_X \times T$  monthly mean values across the ensemble at each grid point $i$ ($\mu_i$)
 \item $N_{var} \times N_X \times T$ standard deviations of ensemble monthly mean values at each grid point $i$ ($\sigma_i$),
 \end{itemize}
 这也就是说，我们保存了指定个月份$T \;=\; 36$ 在所有$N_x$ 个点上的集合平均值和标准方差值（这里 $N_x$ 是变量是二维还是三维的变量有关系）。
 

 最后值得一提的是，由于在淡水和盐度之间没有合适的淡水反馈机制，在没有任何特殊改动的情况，CESM-POP在封闭的内海区域（比如哈德逊湾和地中海）可能会产生一些与实际不符的盐度分布。
当前版本的CESM-POP在非耦合的模拟中强加了一个很强的淡水恢复机制，而在耦合模拟中加入的是边缘海淡水平衡机制。
这些特殊的处理能够保持盐度的平衡，但是对于模式的动力过程造成了虚假的强迫。
因此，本文的工作中我们不去讨论如何在边缘海中正确的做验证，而是将重心限制在开放海域内。

\subsection{验证过程}
 
利用前面所得到的POP-ECT综述文件，我们利用以下的方法来判断一个新的模拟输出结果（比如说改动了代码，或者移植到了新的机器上，或者采用了一个新的编译器选项等)是否和指定的数据集合的分布所描述的海洋气候状态在统计学上是一致。 
由于我们只有五个比较基础的诊断变量，因此我们不需要采用主成分分析的方法。 
这里，我们采用的策略是在每一个给定点上评估新的模拟结果和数据集合之间的标准差。
对于每一个给定点$i$和某一个给定的变量$\tilde{{X}}$， 在给定的时间片$t$上我们采用标准分方法计算$\tilde{{X}}$和数据集合的距离。 
特别的，给定变量$\tilde{{X}}$ 在 $t$时刻的值，$\tilde{{X}} = \{ \tilde{x}_{1,t}, \tilde{x}_{2,t}, \dots, \tilde{x}_{N_X,t}\}$， 那么在给定点$i$ 处变量$\tilde{{X}}$ 在$t$时间的标准分为
\begin{equation*}
Z_{\tilde{x}_{i,t}}=  \frac{\tilde{x}_{i,t} -\mu_{i,t}}{\sigma_{i,t}},
\end{equation*}
这里 $\mu_{i,t}$和$\sigma_{i,t}$分别表示指定的数据集合在点 $i$处，变量$X$在给定的$t$月份的几何平均和标准方差。  

 
下面，为了简洁，对于某一个时间片$t$，我们从相关的变量中去掉时间变量下表。比如说，标准分我们记为$Z_{\tilde{x_i}}$。 
我们假设在每一个点上允许的阈值为$tol_{Z}$，也就是说如果 $Z_{\tilde{x_i}} > tol_{Z}$就表明$i$这个点是一个“不通过”的点。 
由于标准分表示的是一个数与平均值之间的标准方差，所以标准分越大就表明这个新的模拟结果和数据集合所给的气候状态就越远。 
下一步，我们将考察一下所有点中通过标准分标准的点所占的比例。 定义给定变量$\tilde{X}$的标准分通过比例（ZPR）为：
\begin{equation}\label{e:zpr}
ZPR_{\tilde{X}} = \frac{ \#\{i \;|\; \tilde{x_i} \in \tilde{X} \; \land \; |Z_{\tilde{x_i}}| \; \leq \; tol_{Z}\} }{\#\{i \;|\; \tilde{x_i} \in \tilde{X} \} }.
\end{equation}
 
为了给出一个评判给定变量$\tilde{X}$ 是否通过测试的整体性标准，我们对标准分通过比例设置了一个最小阈值($min_{ZPR}$)。 
也就是说，如果$ZPR_{\tilde{X}} \geq min_{ZPR}$成立，则我们认为 $\tilde{X}$通过测试。
默认情况下，标准分的通过阈值为$tol_{Z} \; = \; 3.0$， 而标准分通过比例ZPR的阈值为$min_{ZPR} \; = \; 0.9$。 
换句话说，新的模拟结果中变量$\tilde{X}$要想通过测试，必须保证这个变量在90$\%$以上的点上的值落在在对应点对应变量的集合平均值($\mu$) 的$3.0$ 个标准差之间。
我们对五个独立的诊断变量依次做上面的判断。 
只有当所有的变量都通过测试，我们才认为这个新的模拟结果整体上来说和数据集合在统计意义上是一致的。


 
我们注意到计算得到的标准分随着模拟时间的改变而改变。 
由于海洋运动的时间尺度比较长，本章中大部分的实验我们都将CESM运行36个月。
另外，模拟过程中我们会保存月输出的时间片数据（CAM-ECT中只保存了年平均数据），用来考察数据集合中的海洋状态能否随着时间的延长而稳定下来。 



在后面的章节中我们可以看到，ZPRs通常在几个月的模拟之后便会平稳下来，而且这种平稳的趋势在几个诊断变量中都是相似的。 
因此，除了挑选出合适的标准分阈值以及ZPRs的通过率阈值，我们还选择了一个时间点（$t_C$）
来判断新的运行结果（而不是去检查每个月的数据）。 
于是，集合模拟的时间长度不需要比$t_C$更长。 

\subsection{软件工具}

为了使得用户和开发展都能够使用我们的新的针对POP设计的诊断方法，我们将POP-ECT添加到现成的CESM-ECT Python工具集中（pyCECT v2.0）。
这个工具集已经被集成到当前CESM发布的版本中。 
这个CESM-ECT Python工具集包括了生成CESM特定模块的集合模拟综述文件的工具，以及利用这些集合模拟综述文件来进行统计学一致性检测的工具pyCECT。
由于POP-ECT的综述文件和CAM-ECT的综述文件完全不同，我们利用并行的Python代码pyEnsSumPop来生成POP-ECT综述文件。
具体来讲，从CESM-POP集合模拟的输出文件中，pyEnsSumPop并行的生成一个包含有第\ref{sec:ensemble}节中描述的海洋模式一些统计量的集合综述文件。 
CESM软件工程组将会按照需要生成一个新的POP模拟数据的集合，这个数据集合包含有一个注明了具体改动的软件标签。
POP-ECT所生成的集合综述文件和第\ref{sec:code}节提到的CESM的版本标签将被放到未来发展的模式中。 
有了POP-ECT的综述文件，用户或者开发者就可以利用pyCECT Python工具来评估新的模拟数据的一致性。目前可以选择POP-ECT或者CAM-ECT来对结果进行评估。
新的CESM-POP模拟数据可能来自一个新的机器的移植， 一个新的编译器选项的使用，代码的更新，或者输出数据的改变。
pyCECT评估新的海洋模式模拟结果是否与给定的POP-ECT生成的数据集合是统计意义上一致的，并且从总体上给出一个“通过”或者“不通过”的判断。
另外，在指定的检查时间点$t_C$，每一个变量的标准分通过率都会被给出。 

% %-----------------------------------------------------------------------------
% % -----------------------------------------------------------------------------
% %----------------------------------------------------------------------------
\section{实验} \label{sec:exp}

 
这一节的主要目标是通过一 系列的实验来评估我们的新的POP一致性检测工具在CESM-POP的模拟数据上的效果。
我们的这些实验都是有预判结果的，比如说重新考察一下改变正压求解器的收敛条件所带来的效果。
这些实验都是用的CESM 1.2.2版本来运行，使用CESM-POP作为活跃的海洋模式分量，CICE作为活跃的海冰分量，而大气和路面模式都采用数据来驱动。
因此，不会出现逐年响应的事件（比如厄尔尼诺南方涛动），而且赤道太平洋地区的变化可能会受到人为的抑制。
我们这个特殊的分量模式的配置在CESM的官方文档中被记为“G\_NORMAL\_YEA”分量设置。
CESM的网格分辨率采用“T62\_g16”，对应的海洋和海冰模式分量采用是1度($320 \times 384$)分辨率，垂直方向上有60层，以格林兰岛为偏移极点的偏移网格。 
这些模拟都是在美国国家大气研究中心的黄石超级计算机上使用$96$ 个处理器核心（除非特殊说明了处理器核心的数目）运行得到的。 

 对于这些模拟实验，我们不单单是对某一个时间片做了评估，而是对36个月的数据都进行了评估，以此来观察ZPRs随着时间的变化规律，同时也为$t_C$的选择提供参考依据。
为了从ZPRs的角度来刻画标准分和模拟时间的关系，并且为$tol_{Z}$和$min_{ZPR}$的选择提供参考依据，我们采用了反应曲面法（RSM）\citep{box2007}。 
也就是说，我们提供了变量$\tilde{X}$的反应曲面的图标，这个图表中给出了不同的模拟月份中，满足一系列的标准分阈值条件$Z_{\tilde{x_i}} > tol_{Z}$的点的比例的关于给定阈值$tol_{Z}$的累积分布函数。
最后，如前面提到的那样，我们发现，40个模拟结果组成集合模拟对于我们的实验来说已经足够。
但是我们还是在第 \ref{sec:ens}节进一步的探讨了集合成员的个数的选择。  

为了简洁，尽管我们也分析了其他变量，我们只展示了温度（TEMP）和海表高度（SSH）的结果。 
这两个变量在海洋模式系统有很强的代表性。海表高度和海洋海流动力系统密切相关，而温度是由模型的标量传输决定的。
 

\subsection{正压求解器收敛性条件}

 
首先，我们先用我们新的加强版本的CESM-ECT工具来重新评估一下改变正压求解器收敛性条件所带来的影响。
CESM-POP中正压求解器默认的收敛条件是$10^{-13}$， 我们运行一些采用 $10^{-9}$ 到 $10^{-16}$之间值作为收敛条件的模拟，然后输出所有点上的36个月平均数据。
我们预测采用比默认的收敛条件$10^{-13}$更加严格的条件得到的模拟结果应该是与原结果在气候学上是一致的，但是更送一些的收敛条件将会引入一些误差。


 
图 \ref{fig:RSM-TEMP-tol}和Fig. \ref{fig:RSM-SSH-tol}分别给出了温度和海表高度的反应曲面。 
每张图包含有四个反应曲面：上面两个分别是采用原始默认收敛条件($10^{-13}$)和更严格的收敛条件得到的结果，下面两个是更松的收敛条件（$10^{-10}$和$5.0*10^{-9}$）得到的结果。 
每一个反应曲面中，X轴表示模拟的月份（从1月到36个月），Y轴表示衡量标准分的分布的阈值$tol_{Z}$。这里阈值就是计算方程中ZPR所用的划定标准分满足某个条件的比例时所用到的阈值。
颜色刻度中ZPR采用的是以10\%为间隔的百分比。 
反应曲面对于评估$tol_{Z}$和$min_{ZPR}$的不同组合非常有效。
比如说，考虑变化求解器收敛条件对温度变量的影响。 图中左上角的 \ref{fig:RSM-TEMP-tol}子图显示，原始的收敛条件($10^{-13}$)下，在所有模拟月份中90\% 的点的标准分都小于2.0。
与之相对的，下面的采用为$10^{-10}$收敛条件的子图表明，在第九个模拟月份之后，90\% 的点的标准分要小于3.0， 而在12个分，只有百分之七十到八十左右的网格点的标准分要小于2.0. 
右下角的子图采用的收敛条件进一步放松 到$5.0*10^{-9}$，它的比较低的ZPR比例表明这个例子中引入较大的误差。
我们继续考察图\ref{fig:RSM-SSH-tol} 中关于海表高度的反应曲面，四个子图分别表示与图\ref{fig:RSM-TEMP-tol}中相同的四个收敛条件，可以看到总体趋势与温度的反应曲面很相似。 
对于采用$10^{-13}$为收敛条件的模拟结果中，在除了第六个月的所有模拟月份中， 90\%的点上标准分都要小于2.0。 
与温度变量的反应曲面类似， 收敛条件为$10^{-10}$ 对应的子图可以出来有明显的误差，这个误差在收敛条件为$5.0*10^{-9}$对应的例子中更加明显。 
温度和海表高度的反应曲面中有一个明显的不同就是，温度得到的曲线随着时间的变化更加光滑。 这主要是由于温度的计算中有一个很很要的扩散过程。

 

如果我们在图\ref{fig:RSM-TEMP-tol}和图\ref{fig:RSM-SSH-tol}中固定标准分的衡量阈值，我们就可以很容易的评估ZPR。 
假设我们采用一个比较保守的选择$tol_{Z} \; = \; 3.0$。 
图 \ref{fig:PRZ-tol}给出了温度和海表高度两个变量中，标准分超出阈值 $tol_{Z} \; = \; 3.0$ 的点的百分比。 
如果我们选择ZPR的阈值为$min_{ZPR} \; = \; 0.9$， 也就对应着图\ref{fig:PRZ-tol}中10\%的不通过率，我们可以很明显的看出收敛条件为$10^{-10}$的例子就处于我们定义通过与不通过的边界线上（因此，这个收敛条件值在实际模拟中不能使用）。 
而采用比$10^{-10}$更严格的收敛条件得到的结果的不通过率更低一些，因此，看起来它们的两个变量跟原始结果所得到的变量在统计学上时一致的。
图\ref{fig:PRZ-tol}中的图标很明晰的证明了，随着收敛条件的放松，超出给定标准分阈值的点会增多。 
这个结果比文章\cite{yong2015}中的结果更加清楚。 


\subsection{Processor layouts}

While CESM simulations that are identical except for differing numbers of CESM-POP processor cores yield non-BFB identical results, the results from such simulations 
should represent the same climate state (i.e., they should not be statistically distinguishable). Here we verify that such simulations definitively pass CESM-ECT.  Recall that the simulations comprising our CESM-ECT ensemble were run on 96 cores.  We ran additional simulations on 48, 192,和384 cores.  Note that we are not using threading in CESM-POP at this time.

The response surface plots for 96 cores (labeled ``original'')和384 cores are the top subplots in Fig. \ref{fig:RSM-TEMP-param}和Fig. \ref{fig:RSM-SSH-param} for TEMP和SSH, respectively. These plots show that for both core counts, 90\% of all grid points have a Z-score of less than 2.0 for nearly all simulation months,和as expected, there is little discernable difference between the two core counts for both variables.  As before, we fix the Z-score tolerance at $tol_{Z} \; = \; 3.0$和show the Z-score failure rates for TEMP with all four core count options (48, 96, 192,和384) in Fig. \ref{fig:combine}.  As anticipated, the failure percentages are quite low (below 1.2\%) for all configurations at all monthly time slices, confirming that differences in simulation output due to varying the core count in CESM-POP are not statistically significant和correctly identified as such by the new CESM-ECT methodology.  Note that the corresponding plot for SSH is not provided as is looks similarly good in terms of very low failure rates.

 \subsection{Physical parameters}\label{sec:pp}

 Now we change two physical parameters expected to alter the ocean climate from the tracer equations: the tracer's vertical mixing coefficient for convective instability和the tracer advection scheme.  Results from these modifications should fail the CESM-ECT. First, by default, the vertical mixing coefficient for convective instability (\textit{convect\_diff}) is set to be \textit{convect\_diff} $=\; 10,000$ for the tracer mixing coefficient in the 1\degree CESM-POP configuration.  We increase this parameter by factors of 2, 5,和10, which is expected to increase the vertical mixing in the ocean interior when the density profile is unstable. This should noticeably impact the CEM-POP results due to the different mixing property.  Second, we change the POP tracer advection scheme (\textit{t\_advect\_ctype}) from the default 3rd-order upwind scheme (\textit{upwind3}) to the Lax-Wendroff scheme with 1D flux limiters (\textit{lw\_lim}). This change is also significant和should lead to a different climate state because the associated diffusion和dispersion errors differ.

The response surface plots for increasing \textit{convect\_diff} by a factor of 10 are given in the lower left subplots in Fig. \ref{fig:RSM-TEMP-param}和Fig. \ref{fig:RSM-SSH-param} for TEMP和SSH, respectively.  This change clearly affects the climate state significantly, particularly as compared to changing the CESM-POP core count to 384 as depicted in the upper right subplot in both figures.  In fact, the impact on TEMP of increasing \textit{convect\_diff} in Fig. \ref{fig:RSM-TEMP-param} is almost as strong as changing the solver convergence tolerance to $10^{-9}$ in Fig. \ref{fig:RSM-TEMP-tol}.  The change of the advection scheme also leads to different climate state, evident in the lower right subplots in Fig. \ref{fig:RSM-TEMP-param}和Fig. \ref{fig:RSM-SSH-param} for TEMP和SSH, respectively.  Note that the Z-scores at nearly every grid point are failing.

The Z-score failure rates for $tol_{Z} \; = \; 3.0$ are shown in Fig. \ref{fig:PRZ-temp-param} for advection scheme change as well as all the modifications to the tracer vertical mixing coefficient for convective instability.  If we choose a ZPR threshold of $min_{ZPR} \; = \; 0.9$, which corresponds to a maximum of 10\% failure rate,  then doubling the vertical mixing coefficient (\textit{convect\_diff}*2) is borderline in terms of passing or failing.  The remaining tests clearly fail for both TEMP和SSH, as expected. Based on our experiments thus far, choosing a Z-score tolerance of $tol_{Z} \; = \; 3.0$和a ZPR threshold of $min_{ZPR} \; = \; 0.9$ yields the expected outcome,和these parameter settings are the default for the pyCECT tool.  


 \subsection{Simulation length}


%In particular, in cases which should pass (such as changing the core counts), more than 90\% of the points have Z-scores smaller than 3.0 at all monthly time slices.  While for cases which use different physical schemes (Section \ref{sec:pp}), the percentage of points which have Z-scores smaller than 3.0 is significantly lower than 90 \%.

 Our experiments in Fig. \ref{fig:PRZ-temp-param} indicate that the percentage of grid points with failing Z-scores differs little from month to month after the first 12 months for both TEMP和SSH.  This conclusion can also be reached from Fig. \ref{fig:RSM-TEMP-param}和Fig. \ref{fig:RSM-SSH-param} for TEMP和SSH, respectively.  In particular, the response of SSH to the initial temperature perturbation is largely stabilized after 12 months. The SSH may be affected through the circulation change resulting from the change of density stratification.  Based on our experimental results, evaluating the output at a single well-chosen checkpoint time $t_C$ appears reasonable.

 We generally choose $t_C \;=\; 12$ to minimize the computational requirements of creating the ensemble for each candidate CESM tag. (The ensemble simulations runs can be length $t_C$.)  Consider the surface plots for month $t_C \;=\; 12$ in Fig. \ref{fig:zscore-combine} that illustrate the Z-score values for SST as compared to the ensemble for four different model configurations.  The top subplot is the original case.  The second plot from the top is the result of changing the number of CESM-POP processor cores to 384, which resembles the topmost plot as expected.  While the patterns are not identical for the upper two plots, the Z-score magnitudes和distributions are similar, indicating a degree of statistical consistency when changing the number of processors.  In contrast, increasing the tracer mixing coefficient for convective instability by a factor of 10 was shown to change the climate state in Sect. \ref{sec:pp},和this result is clearly evident in the Z-score at month 12 in the third plot from the top of Fig. \ref{fig:zscore-combine}.  Finally, the bottom subplot in Fig. \ref{fig:zscore-combine} indicates a largely altered climate state due to the use of a different advection scheme, which corroborates the substantial effects seen in Fig. \ref{fig:RSM-TEMP-param}和Fig. \ref{fig:RSM-SSH-param}.  Using a different advection scheme significantly changes the numerical dissipation和diffusion associated with the scheme \citep{tseng2008}和effectively influences the circulation pattern和structure in the ocean model \citep[e.g.,][]{tseng2006}. 
In particular, the Lax-Wendroff scheme with flux limiters can introduce excessive numerical mixing which may interact with the physical mixing of temperature和salinity, though it can result in a much smoother solution in general.


% %-----------------------------------------------------------------------------
% % -----------------------------------------------------------------------------
% %----------------------------------------------------------------------------
\section{Ensemble size } \label{sec:ens}

The size (i.e., number of members) of the ensemble must be large enough to sufficiently capture ocean model variability, but as small as possible for computational efficiency.  In this section, we discuss the sensitivity of POP-ECT to ensemble size.  We setup experiments to determine the false positive rate associated with multiple ensembles sizes as follows.
First, we generate a total of 80 ensemble members that differ by an $\mathcal{O}(10^{-14})$ perturbation to the initial ocean temperature field.  Second, from the 80 members, we remove 10 to use as our test set. Next, from the remaining 70 members, we create ensembles of sizes 10, 20, 30, 40, 50,和60.  In particular, for each ensemble size, we do 100 random draws for each ensemble size from the set of 70 members, resulting in 100 distinct ensembles corresponding to each ensemble size. Then for each ensemble size, we run POP-ECT at $t_c = 12$ months for each of the 10 members of the test set with all 100 ensembles of that size, resulting in 1000 tests per ensemble size.   We consider the measured experimental failure rate to be the type I error, or ``false positive'' rate.  Because the test set和the ensemble members are all drawn from the larger 80 member collection that represents a statistically consistent climate, the Z-score failure rate would ideally be as low as possible. 

Figure \ref{fig:temp_ens_80} shows the results of performing these experiments for variables TEMP和SSH. The x-axis indicates the ensemble size,和the y-axis indicates the Z-score failure rate.  For each ensemble size, the squares denote the mean和the error bars indicate one standard deviation of uncertainty.  As expected,  as the ensemble size increases, the false positive rate decreases和the range of uncertainty shrinks.  However,  increasing the ensemble size has diminishing returns; the improvement in false positive rate when using 20 instead of 10 members is much greater than the improvement gained by using 60 instead of 50 members.  We choose an ensemble size of 40 as improvement beyond that is marginal和we balance a low false positive rate with keeping the cost of ensemble generation low.

% %-----------------------------------------------------------------------------
% % -----------------------------------------------------------------------------
% %----------------------------------------------------------------------------
 \conclusions[Conclusions和Future Work]\label{sec:concl}


Because the CESM-POP ocean model is widely-used和critical to many climate simulations, assuring its quality is critical. However, the chaotic nature of ocean dynamics often leads to simulation results that are not identical in the presence of minor differences, such as a change in processor core count for the simulation.  Therefore, the ability to easily determine whether differences in model results are statistically significant is important to both climate scientists和model developers.  The ensemble methodology developed for evaluating consistency with atmospheric data, CAM-ECT, was not appropriate for ocean simulation data based on its differing characteristics.  Therefore, we developed a new ocean model-specific methodology for statistical consistency testing, POP-ECT, that allows for the subjective detection of statistically significant changes in CESM-POP.  Together with the new methodology, using an appropriately-sized ensemble is critical as well. Our experiments indicate the appropriateness of the new approach for detecting differences in the model ocean state. The addition of POP-ECT to the CESM-ECT suite of tools has greatly enhanced the capability to ensure quality CESM simulations.

We plan to extend this work in a number of ways.  First, the existing spatial approach lends itself to the examination of regional ocean diagnostics.  For example, named oceans could be identified individually as the source of failure if the global test fails.  Enabling the move from coarse- to fine-grain diagnostics would facilitate determining the root cause of an error or difference.  Second, we plan to extend the evaluation of the effects of data compression on climate data in \cite{baker2014} to ocean model data和will use the testing methodology presented here to evaluate the impact. The ability to determine whether changes in the ocean state are statically significant or not due to data loss during compression is critical to the acceptance of compression as a tool to reduce data volumes for ocean simulation data.


% % -----------------------------------------------------------------------------
% % ----------------- Section Code--------------------------------------
% % -----------------------------------------------------------------------------

  \section{Code availability}\label{sec:code}

The CESM-ECT Python tools (pyCECT v2.0) can be obtained independently of CESM from NCAR's public git repository (\url{https://github.com/NCAR/PyCECT/releases}).  The version of CESM used for our experiments, CESM 1.2.2, is available at \url{http://www.cesm.ucar.edu/models/cesm1.2}. The CESM-ECT software tools are also included in the CESM public releases, with the POP-ECT addition available starting with the CESM 2.0 release series. 
%Alternatively, the tool can also be obtained as a subset of the CIME tools (statistical\_ensemble\_test), which are available at {\url{https://github.com/CESM-Development/cime}.  
CESM-POP simulation data is available from the corresponding author upon request.
